{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5884dd",
   "metadata": {},
   "source": [
    "<a id='FEMB'></a>\n",
    "\n",
    "# Restaurant Fake Review Detection # 3\n",
    "\n",
    "- __[Feature Engineering](#FE)__\n",
    "- __[Model Building](#MB)__\n",
    "\n",
    "    - [Text Analysis (CNN, LSTM)](#TA)\n",
    "\n",
    "    - [Classification Algorithms](#CA)\n",
    "    \n",
    "    \n",
    "To navigate to each section and subsection, please use this [link]() where you can use embedded internal links within this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91257fcd",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6070cd5",
   "metadata": {},
   "source": [
    "<a id='FE'></a>\n",
    "\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a021a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required for analysis\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import attrgetter\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306ae586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.read_pickle(\"./org_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed649451",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb31995",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96fce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the maximum number of reviews each reviewer has left in a day and drop the reviewerID.\n",
    "\n",
    "max_temp = df_join.groupby(['reviewerID','date'])['reviewerID'].count().reset_index(name='count')\n",
    "max_temp_new = max_temp.groupby(\"reviewerID\", as_index = False).max()\n",
    "\n",
    "df_join = pd.merge(df_join,\n",
    "                 max_temp_new[['reviewerID', 'count']],\n",
    "                 on='reviewerID')\n",
    "df_join.rename({'count': 'maxReview_a_day'}, axis=1, inplace=True)  # rename the count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed42e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>rating</th>\n",
       "      <th>flagged</th>\n",
       "      <th>reviewer_location</th>\n",
       "      <th>yelpJoinDate</th>\n",
       "      <th>reviewer_friendCount</th>\n",
       "      <th>reviewer_reviewCount</th>\n",
       "      <th>reviewer_firstCount</th>\n",
       "      <th>reviewer_usefulCount</th>\n",
       "      <th>reviewer_coolCount</th>\n",
       "      <th>reviewer_funnyCount</th>\n",
       "      <th>reviewer_complimentCount</th>\n",
       "      <th>reviewer_tipCount</th>\n",
       "      <th>reviewer_fanCount</th>\n",
       "      <th>restaurant_reviewCount</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>categories</th>\n",
       "      <th>PriceRange</th>\n",
       "      <th>maxReview_a_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7226</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>probably the best meal i have ever had everyth...</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>841</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Restaurants, American (New)</td>\n",
       "      <td>Over $61</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7227</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>great atmosphere nice wines try the homemade r...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>578</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>very good homemade pasta wonderful outdoor sea...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>$31-60</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7229</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>their pizza is very good i dont like their atm...</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1543</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7230</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>great sandwiches worth the quickly moving line...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1461</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Mexican</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>my favorite chinese restaurant in chicago best...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Chinese</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7232</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>i started out liking this place much more but ...</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>this place is steady its got a nice fun atmosp...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>$31-60</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>uninspired nice atmosphere and service but the...</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, American (New)</td>\n",
       "      <td>Over $61</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>if you can get over the occasionally terrible ...</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>684</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Other</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>good pho nothing amazing but good pho</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Under $10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>overrated for brunch really didnt love the food</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>2006-01</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>$31-60</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                      reviewContent  rating  \\\n",
       "7226 2012-04-12  probably the best meal i have ever had everyth...       5   \n",
       "7227 2012-04-12  great atmosphere nice wines try the homemade r...       4   \n",
       "7228 2012-04-12  very good homemade pasta wonderful outdoor sea...       4   \n",
       "7229 2012-04-12  their pizza is very good i dont like their atm...       3   \n",
       "7230 2012-04-12  great sandwiches worth the quickly moving line...       4   \n",
       "7231 2012-04-12  my favorite chinese restaurant in chicago best...       4   \n",
       "7232 2012-04-12  i started out liking this place much more but ...       3   \n",
       "7233 2012-04-12  this place is steady its got a nice fun atmosp...       4   \n",
       "7234 2012-04-12  uninspired nice atmosphere and service but the...       3   \n",
       "7235 2012-04-12  if you can get over the occasionally terrible ...       4   \n",
       "7236 2012-04-12              good pho nothing amazing but good pho       3   \n",
       "7237 2012-04-12    overrated for brunch really didnt love the food       3   \n",
       "\n",
       "     flagged reviewer_location yelpJoinDate  reviewer_friendCount  \\\n",
       "7226       N       Chicago, IL      2006-01                     8   \n",
       "7227       N       Chicago, IL      2006-01                     8   \n",
       "7228       N       Chicago, IL      2006-01                     8   \n",
       "7229       N       Chicago, IL      2006-01                     8   \n",
       "7230       N       Chicago, IL      2006-01                     8   \n",
       "7231       N       Chicago, IL      2006-01                     8   \n",
       "7232       N       Chicago, IL      2006-01                     8   \n",
       "7233       N       Chicago, IL      2006-01                     8   \n",
       "7234       N       Chicago, IL      2006-01                     8   \n",
       "7235       N       Chicago, IL      2006-01                     8   \n",
       "7236       N       Chicago, IL      2006-01                     8   \n",
       "7237       N       Chicago, IL      2006-01                     8   \n",
       "\n",
       "      reviewer_reviewCount  reviewer_firstCount  reviewer_usefulCount  \\\n",
       "7226                    48                    0                     7   \n",
       "7227                    48                    0                     7   \n",
       "7228                    48                    0                     7   \n",
       "7229                    48                    0                     7   \n",
       "7230                    48                    0                     7   \n",
       "7231                    48                    0                     7   \n",
       "7232                    48                    0                     7   \n",
       "7233                    48                    0                     7   \n",
       "7234                    48                    0                     7   \n",
       "7235                    48                    0                     7   \n",
       "7236                    48                    0                     7   \n",
       "7237                    48                    0                     7   \n",
       "\n",
       "      reviewer_coolCount  reviewer_funnyCount  reviewer_complimentCount  \\\n",
       "7226                   2                    2                         0   \n",
       "7227                   2                    2                         0   \n",
       "7228                   2                    2                         0   \n",
       "7229                   2                    2                         0   \n",
       "7230                   2                    2                         0   \n",
       "7231                   2                    2                         0   \n",
       "7232                   2                    2                         0   \n",
       "7233                   2                    2                         0   \n",
       "7234                   2                    2                         0   \n",
       "7235                   2                    2                         0   \n",
       "7236                   2                    2                         0   \n",
       "7237                   2                    2                         0   \n",
       "\n",
       "      reviewer_tipCount  reviewer_fanCount  restaurant_reviewCount  \\\n",
       "7226                  0                  0                     841   \n",
       "7227                  0                  0                     578   \n",
       "7228                  0                  0                     481   \n",
       "7229                  0                  0                    1543   \n",
       "7230                  0                  0                    1461   \n",
       "7231                  0                  0                     607   \n",
       "7232                  0                  0                     947   \n",
       "7233                  0                  0                     702   \n",
       "7234                  0                  0                     581   \n",
       "7235                  0                  0                     684   \n",
       "7236                  0                  0                     800   \n",
       "7237                  0                  0                    1303   \n",
       "\n",
       "      restaurant_rating                   categories PriceRange  \\\n",
       "7226                4.5  Restaurants, American (New)   Over $61   \n",
       "7227                4.0         Restaurants, Italian     $11-30   \n",
       "7228                4.0         Restaurants, Italian     $31-60   \n",
       "7229                4.0                        Other     $11-30   \n",
       "7230                4.0         Restaurants, Mexican     $11-30   \n",
       "7231                4.0         Restaurants, Chinese     $11-30   \n",
       "7232                4.0                        Other     $11-30   \n",
       "7233                4.0                        Other     $31-60   \n",
       "7234                4.0  Restaurants, American (New)   Over $61   \n",
       "7235                3.5                        Other     $11-30   \n",
       "7236                4.0                        Other  Under $10   \n",
       "7237                4.0                        Other     $31-60   \n",
       "\n",
       "      maxReview_a_day  \n",
       "7226               12  \n",
       "7227               12  \n",
       "7228               12  \n",
       "7229               12  \n",
       "7230               12  \n",
       "7231               12  \n",
       "7232               12  \n",
       "7233               12  \n",
       "7234               12  \n",
       "7235               12  \n",
       "7236               12  \n",
       "7237               12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviews left by a reviewer whose maxReview_a_day = 12\n",
    "\n",
    "max_review = df_join.loc[df_join['maxReview_a_day'].idxmax()].reviewerID   \n",
    "df_join.loc[df_join['reviewerID']==max_review, df_join.columns != 'reviewerID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c08d3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a7718",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eacf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuate the standard deviation of ratings of each reviewer.\n",
    "\n",
    "meansd = df_join.groupby(['reviewerID'], as_index=False).agg({'rating':['std']})\n",
    "meansd.columns = ['reviewerID', 'rating_std']\n",
    "df_join = pd.merge(df_join, meansd[['reviewerID', 'rating_std']], on='reviewerID')\n",
    "\n",
    "df_join['rating_std'] = df_join['rating_std'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93ede4",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d8a25",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fea1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time differences between 'date' and 'yelpJoinDate', and remove 'yelpJoinDate' and 'date_mo_yr'. \n",
    "\n",
    "df_join['date_mo_yr'] = pd.to_datetime(df_join['date']).dt.to_period('M')\n",
    "df_join['sinceJoin_months'] = (df_join['date_mo_yr'] - df_join['yelpJoinDate']).apply(attrgetter('n'))\n",
    "\n",
    "df_join = df_join.drop(['yelpJoinDate', 'date_mo_yr'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c1abc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1c103",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35c7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of words and uppercase letters in each reviewContent.\n",
    "\n",
    "df_join['wordCount'] = df_join.reviewContent.apply(lambda x: len(x.split()))\n",
    "df_join['uppercaseCount'] = df_join.reviewContent.apply(lambda x: sum(1 for c in x if c.isupper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9da626",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af504e95",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad6c79",
   "metadata": {},
   "source": [
    "Most of the reviewers are in Chicago, IL. Rather than having all infrequent location information, create a new column 'reviewer_restaurant_loc_match' to indicate whether reviewers are in Chicago or not as the restaurants in this dataset are in the Chicago area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6212a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'reviewer_location' to 'reviewer_restaurant_loc_match'\n",
    "df_join.rename(columns = {'reviewer_location':'reviewer_restaurant_loc_match'}, inplace = True)\n",
    "\n",
    "# Compare reviewer's location & restuarant location (Chicago, IL) and see if they match (Y/N)\n",
    "for i in range(df_join.shape[0]):\n",
    "    if df_join.loc[df_join.index[i], 'reviewer_restaurant_loc_match'] == 'Chicago, IL':\n",
    "        df_join.loc[df_join.index[i], 'reviewer_restaurant_loc_match'] = 'Y'\n",
    "    else:\n",
    "        df_join.loc[df_join.index[i], 'reviewer_restaurant_loc_match'] = 'N'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756c1e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342ce71",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbb7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two columns (polarity and subjectivity) using sentiment analysis with review contents.\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df_join[\"polarity\"] = df_join[\"reviewContent\"].apply(pol)\n",
    "df_join[\"subjectivity\"] = df_join[\"reviewContent\"].apply(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39ef3f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4324387f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da062c",
   "metadata": {},
   "source": [
    "The 'reviewer_usefulCount', 'reviewer_coolCount', 'reviewer_funnyCount', 'reviewer_complimentCount', 'reviewer_tipCount' have very high correlations with each other. Hence, we create a new feature 'reviewer_upvoteCount' by summing the above features, and drop them to avoid multicolliearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c04fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns to avoid multicolliearity. \n",
    "\n",
    "df_join['reviewer_upvoteCount'] = df_join['reviewer_usefulCount'] + df_join['reviewer_coolCount'] + df_join['reviewer_funnyCount'] + df_join['reviewer_complimentCount'] + df_join['reviewer_tipCount']\n",
    "df_join = df_join.drop(['reviewer_usefulCount', 'reviewer_coolCount', 'reviewer_funnyCount', 'reviewer_complimentCount', 'reviewer_tipCount'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66670d1f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366cd9d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33bbc3",
   "metadata": {},
   "source": [
    "Also, the 'reviewer_fanCount' and 'reviewer_friendCount' have a correlation of 0.89. Both of them represent the number of connections of each reviewer. We keep the 'reviewer_friendCount' and drop the 'reviewer_fanCount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f955562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'reviewer_fanCount'.\n",
    "\n",
    "df_join = df_join.drop(['reviewer_fanCount'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255abf",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b8593",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a7920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month', 'day', 'weekday' columns using the 'date' column. \n",
    "\n",
    "df_join['month'] = df_join.date.dt.month\n",
    "df_join['day'] = df_join.date.dt.day\n",
    "df_join['weekday'] = df_join.date.dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f763cf",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1d2d8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ccc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, drop 'reviewerID' and 'date'. \n",
    "\n",
    "df_join = df_join.drop(['reviewerID', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07e6e7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383a5d5",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb2655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding (3 attributes)\n",
    "df_encoded = pd.get_dummies(data=df_join, columns=['categories', 'PriceRange', 'weekday'])\n",
    "\n",
    "\n",
    "\n",
    "# Label Encoding (1 attribute, 1 class)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded['reviewer_restaurant_loc_match'] = le.fit_transform(df_encoded.reviewer_restaurant_loc_match.values)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded['flagged'] = le.fit_transform(df_encoded.flagged.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994322df",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5891b0",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac122d66",
   "metadata": {},
   "source": [
    "Now we have 37 attributes including the response with approximately 27,000 reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d705687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26956 entries, 0 to 26955\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   reviewContent                            26956 non-null  object \n",
      " 1   rating                                   26956 non-null  int64  \n",
      " 2   flagged                                  26956 non-null  int32  \n",
      " 3   reviewer_restaurant_loc_match            26956 non-null  int32  \n",
      " 4   reviewer_friendCount                     26956 non-null  int64  \n",
      " 5   reviewer_reviewCount                     26956 non-null  int64  \n",
      " 6   reviewer_firstCount                      26956 non-null  int64  \n",
      " 7   restaurant_reviewCount                   26956 non-null  int64  \n",
      " 8   restaurant_rating                        26956 non-null  float64\n",
      " 9   maxReview_a_day                          26956 non-null  int64  \n",
      " 10  rating_std                               26956 non-null  float64\n",
      " 11  sinceJoin_months                         26956 non-null  int64  \n",
      " 12  wordCount                                26956 non-null  int64  \n",
      " 13  uppercaseCount                           26956 non-null  int64  \n",
      " 14  polarity                                 26956 non-null  float64\n",
      " 15  subjectivity                             26956 non-null  float64\n",
      " 16  reviewer_upvoteCount                     26956 non-null  int64  \n",
      " 17  month                                    26956 non-null  int64  \n",
      " 18  day                                      26956 non-null  int64  \n",
      " 19  categories_Other                         26956 non-null  uint8  \n",
      " 20  categories_Restaurants, American (New)   26956 non-null  uint8  \n",
      " 21  categories_Restaurants, Chinese          26956 non-null  uint8  \n",
      " 22  categories_Restaurants, Italian          26956 non-null  uint8  \n",
      " 23  categories_Restaurants, Mexican          26956 non-null  uint8  \n",
      " 24  categories_Restaurants, Modern European  26956 non-null  uint8  \n",
      " 25  categories_Restaurants, Pizza            26956 non-null  uint8  \n",
      " 26  categories_Restaurants, Steakhouses      26956 non-null  uint8  \n",
      " 27  PriceRange_$11-30                        26956 non-null  uint8  \n",
      " 28  PriceRange_$31-60                        26956 non-null  uint8  \n",
      " 29  PriceRange_Over $61                      26956 non-null  uint8  \n",
      " 30  PriceRange_Under $10                     26956 non-null  uint8  \n",
      " 31  weekday_Friday                           26956 non-null  uint8  \n",
      " 32  weekday_Monday                           26956 non-null  uint8  \n",
      " 33  weekday_Saturday                         26956 non-null  uint8  \n",
      " 34  weekday_Sunday                           26956 non-null  uint8  \n",
      " 35  weekday_Thursday                         26956 non-null  uint8  \n",
      " 36  weekday_Tuesday                          26956 non-null  uint8  \n",
      " 37  weekday_Wednesday                        26956 non-null  uint8  \n",
      "dtypes: float64(4), int32(2), int64(12), object(1), uint8(19)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb18a8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca0485",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c065622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20217, 37) (6739, 37) (20217,) (6739,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X = df_encoded.drop(['flagged'], axis=1)\n",
    "Y = df_encoded['flagged'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143ec5b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683e291",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb8a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 'reviewContent' from the training and test sets.\n",
    "\n",
    "X_train_num_cat = X_train.drop('reviewContent', axis=1)\n",
    "X_train_text = X_train['reviewContent'].copy()\n",
    "\n",
    "X_test_num_cat = X_test.drop('reviewContent', axis=1)\n",
    "X_test_text = X_test['reviewContent'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f6bbe",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d9159",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b00a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (min-max sclaing)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame\n",
    "\n",
    "minmaxscale = MinMaxScaler()\n",
    "\n",
    "col_names = X_train_num_cat.columns\n",
    "\n",
    "X_train_num_cat_scaled = minmaxscale.fit_transform(X_train_num_cat)\n",
    "X_train_num_cat_scaled = DataFrame(X_train_num_cat_scaled, columns = col_names)\n",
    "\n",
    "X_test_num_cat_scaled = minmaxscale.transform(X_test_num_cat)\n",
    "X_test_num_cat_scaled = DataFrame(X_test_num_cat_scaled, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43435073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer_restaurant_loc_match</th>\n",
       "      <th>reviewer_friendCount</th>\n",
       "      <th>reviewer_reviewCount</th>\n",
       "      <th>reviewer_firstCount</th>\n",
       "      <th>restaurant_reviewCount</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>maxReview_a_day</th>\n",
       "      <th>rating_std</th>\n",
       "      <th>sinceJoin_months</th>\n",
       "      <th>...</th>\n",
       "      <th>PriceRange_$31-60</th>\n",
       "      <th>PriceRange_Over $61</th>\n",
       "      <th>PriceRange_Under $10</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.020307</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.268339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.443919</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.191197</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350382</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426881</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.158069</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  reviewer_restaurant_loc_match  reviewer_friendCount  \\\n",
       "0    0.50                            0.0              0.002975   \n",
       "1    0.00                            1.0              0.000000   \n",
       "2    1.00                            1.0              0.001275   \n",
       "3    0.75                            1.0              0.002125   \n",
       "4    0.75                            1.0              0.000000   \n",
       "\n",
       "   reviewer_reviewCount  reviewer_firstCount  restaurant_reviewCount  \\\n",
       "0              0.020307             0.003476                0.268339   \n",
       "1              0.005364             0.001159                0.443919   \n",
       "2              0.039847             0.002317                0.191197   \n",
       "3              0.001149             0.000000                0.426881   \n",
       "4              0.007280             0.002317                0.158069   \n",
       "\n",
       "   restaurant_rating  maxReview_a_day  rating_std  sinceJoin_months  ...  \\\n",
       "0           0.000000              0.0    0.000000          0.317647  ...   \n",
       "1           0.333333              0.0    0.000000          0.352941  ...   \n",
       "2           0.333333              0.0    0.350382          0.047059  ...   \n",
       "3           0.333333              0.0    0.000000          0.000000  ...   \n",
       "4           0.333333              0.0    0.000000          0.564706  ...   \n",
       "\n",
       "   PriceRange_$31-60  PriceRange_Over $61  PriceRange_Under $10  \\\n",
       "0                0.0                  0.0                   0.0   \n",
       "1                0.0                  0.0                   0.0   \n",
       "2                0.0                  0.0                   0.0   \n",
       "3                1.0                  0.0                   0.0   \n",
       "4                0.0                  0.0                   0.0   \n",
       "\n",
       "   weekday_Friday  weekday_Monday  weekday_Saturday  weekday_Sunday  \\\n",
       "0             0.0             0.0               0.0             0.0   \n",
       "1             0.0             1.0               0.0             0.0   \n",
       "2             1.0             0.0               0.0             0.0   \n",
       "3             0.0             0.0               0.0             1.0   \n",
       "4             0.0             1.0               0.0             0.0   \n",
       "\n",
       "   weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \n",
       "0               0.0              1.0                0.0  \n",
       "1               0.0              0.0                0.0  \n",
       "2               0.0              0.0                0.0  \n",
       "3               0.0              0.0                0.0  \n",
       "4               0.0              0.0                0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_cat_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f49de9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewer_restaurant_loc_match</th>\n",
       "      <th>reviewer_friendCount</th>\n",
       "      <th>reviewer_reviewCount</th>\n",
       "      <th>reviewer_firstCount</th>\n",
       "      <th>restaurant_reviewCount</th>\n",
       "      <th>restaurant_rating</th>\n",
       "      <th>maxReview_a_day</th>\n",
       "      <th>rating_std</th>\n",
       "      <th>sinceJoin_months</th>\n",
       "      <th>...</th>\n",
       "      <th>PriceRange_$31-60</th>\n",
       "      <th>PriceRange_Over $61</th>\n",
       "      <th>PriceRange_Under $10</th>\n",
       "      <th>weekday_Friday</th>\n",
       "      <th>weekday_Monday</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.172031</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.327970</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.253546</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024012</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>0.191197</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.323237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287269</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  reviewer_restaurant_loc_match  reviewer_friendCount  \\\n",
       "0    0.75                            1.0              0.010625   \n",
       "1    1.00                            0.0              0.024012   \n",
       "2    1.00                            0.0              0.003612   \n",
       "3    1.00                            1.0              0.000000   \n",
       "4    0.50                            0.0              0.000425   \n",
       "\n",
       "   reviewer_reviewCount  reviewer_firstCount  restaurant_reviewCount  \\\n",
       "0              0.172031             0.022016                0.327970   \n",
       "1              0.052490             0.030127                0.191197   \n",
       "2              0.062835             0.013905                0.323237   \n",
       "3              0.001916             0.000000                0.287269   \n",
       "4              0.005364             0.000000                0.323237   \n",
       "\n",
       "   restaurant_rating  maxReview_a_day  rating_std  sinceJoin_months  ...  \\\n",
       "0           0.333333         0.090909    0.253546          0.411765  ...   \n",
       "1           0.333333         0.000000    0.000000          0.152941  ...   \n",
       "2           0.333333         0.000000    0.000000          0.000000  ...   \n",
       "3           0.333333         0.000000    0.000000          0.000000  ...   \n",
       "4           0.333333         0.000000    0.000000          0.011765  ...   \n",
       "\n",
       "   PriceRange_$31-60  PriceRange_Over $61  PriceRange_Under $10  \\\n",
       "0                1.0                  0.0                   0.0   \n",
       "1                0.0                  0.0                   0.0   \n",
       "2                0.0                  0.0                   1.0   \n",
       "3                1.0                  0.0                   0.0   \n",
       "4                0.0                  0.0                   1.0   \n",
       "\n",
       "   weekday_Friday  weekday_Monday  weekday_Saturday  weekday_Sunday  \\\n",
       "0             0.0             1.0               0.0             0.0   \n",
       "1             0.0             0.0               0.0             0.0   \n",
       "2             0.0             0.0               0.0             0.0   \n",
       "3             0.0             0.0               0.0             0.0   \n",
       "4             0.0             1.0               0.0             0.0   \n",
       "\n",
       "   weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \n",
       "0               0.0              0.0                0.0  \n",
       "1               0.0              1.0                0.0  \n",
       "2               0.0              0.0                1.0  \n",
       "3               0.0              0.0                1.0  \n",
       "4               0.0              0.0                0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_num_cat_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16944b19",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57decc9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b1aae",
   "metadata": {},
   "source": [
    "<a id='MB'></a>\n",
    "\n",
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55fdb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of genuine reviews:  20750 \n",
      "Total number of fake reviews:  6206 \n",
      "Baseline model (initial guess) - Accuracy:  76.98 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of genuine reviews: \", np.count_nonzero(Y == 0), \"\\nTotal number of fake reviews: \", np.count_nonzero(Y == 1), \"\\nBaseline model (initial guess) - Accuracy: \", round(np.count_nonzero(Y == 0) / Y.shape[0], 4) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6ff0c",
   "metadata": {},
   "source": [
    "<a id='TA'></a>\n",
    "\n",
    "## Text Analysis (Natural Language Processing & Deep Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d84f2",
   "metadata": {},
   "source": [
    "My original idea was to build a classifier using only text data (reviewContent) with Natural Language Processing and Deep Learning techniques, and add the binary outcomes (Fake / Genuine) to the original dataset as a new column, so that I can take into account the raw text data, in addition to the characteristics of text data (word count, polarity score, uppercase letter count, etc). \n",
    "\n",
    "Unfortunately, the text classifier is overfitting even after numerous attempts to resolve the problem by dropping out nodes, adjusting embedding size, etc. So the outcome from this classifier will not be used since the results would negatively affect the performance if the new feature is added to the original dataset. \n",
    "\n",
    "But I am leaving the code/results in this notebook so I can come back to this later and retry improving it, or get feedbacks from other experts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "506b9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, LSTM\n",
    "\n",
    "# Tokenization - train\n",
    "docs_train = X_train_text.astype(str).values.tolist()\n",
    "token = Tokenizer(num_words = 500)\n",
    "token.fit_on_texts(docs_train)\n",
    "X_train_seq = token.texts_to_sequences(docs_train)\n",
    "\n",
    "# Padding (make each list of the same length) - train\n",
    "padded_X_train = pad_sequences(X_train_seq, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ce974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization & Padding - test\n",
    "docs_test = X_test_text.astype(str).values.tolist()\n",
    "x_test_seq = token.texts_to_sequences(docs_test)\n",
    "padded_X_test = pad_sequences(x_test_seq, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978e1905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "203/203 [==============================] - 20s 93ms/step - loss: 0.5130 - accuracy: 0.7666 - val_loss: 0.5127 - val_accuracy: 0.7682\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 19s 95ms/step - loss: 0.4928 - accuracy: 0.7713 - val_loss: 0.5025 - val_accuracy: 0.7664\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 19s 94ms/step - loss: 0.4797 - accuracy: 0.7695 - val_loss: 0.5007 - val_accuracy: 0.7712\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 19s 94ms/step - loss: 0.4716 - accuracy: 0.7751 - val_loss: 0.5098 - val_accuracy: 0.7506\n",
      "Epoch 5/10\n",
      "203/203 [==============================] - 19s 94ms/step - loss: 0.4602 - accuracy: 0.7808 - val_loss: 0.4997 - val_accuracy: 0.7709\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 19s 95ms/step - loss: 0.4472 - accuracy: 0.7888 - val_loss: 0.5300 - val_accuracy: 0.7293\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 19s 96ms/step - loss: 0.4198 - accuracy: 0.8042 - val_loss: 0.5523 - val_accuracy: 0.7093\n",
      "Epoch 8/10\n",
      "203/203 [==============================] - 22s 109ms/step - loss: 0.3882 - accuracy: 0.8242 - val_loss: 0.5858 - val_accuracy: 0.6891\n",
      "Epoch 9/10\n",
      "203/203 [==============================] - 20s 100ms/step - loss: 0.3506 - accuracy: 0.8400 - val_loss: 0.6123 - val_accuracy: 0.7040\n",
      "Epoch 10/10\n",
      "203/203 [==============================] - 20s 100ms/step - loss: 0.3077 - accuracy: 0.8628 - val_loss: 0.7236 - val_accuracy: 0.6597\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.7236 - accuracy: 0.6597\n",
      "\n",
      " Accuracy: 0.6597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using CNN and LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(500, 100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "record = model.fit(padded_X_train, Y_train, batch_size=100, epochs=10, validation_data=(padded_X_test, Y_test))\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_X_test, Y_test)[1]))\n",
    "\n",
    "\n",
    "Y_val_loss = record.history['val_loss']\n",
    "Y_loss = record.history['loss']\n",
    "X_len = numpy.arange(len(Y_loss))\n",
    "plt.plot(X_len, Y_val_loss, marker='.', c=\"red\", label=\"Loss from Test\")\n",
    "plt.plot(X_len, Y_loss, marker='.', c=\"blue\", label=\"Loss from Train\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593c9cc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5591e",
   "metadata": {},
   "source": [
    "<a id='CA'></a>\n",
    "\n",
    "## Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854b162",
   "metadata": {},
   "source": [
    "For classification problems, there are several metrics in addition to accuracy, which can be used to evaluate classifiers, such as recall and precision.\n",
    "\n",
    "\n",
    "- Recall = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "- Precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "\n",
    "where TP: true positive, FP: false positive, and FN: false negative which can be obtained from confusion matrix. \n",
    "\n",
    "The relative importance of recall and precision dependes on situations. In the context of this problem where the goal is to filter out fake reviews and hide them from other users, it would be better to show only genuine reviews even if some of genuine reviews could be filtered out due to classifiers' errors, than failing to filter out fake reviews and letting other users to see them because a single review could bring a negative effect to businesses and customers. In this case, high precision is desired instead of high recall. \n",
    "\n",
    "The following is the summary of the classification results based on 10-fold cross validations:\n",
    "\n",
    "- [XGBoost](#XGB) (Accuracy: 90.5% / Precision: 80.1% / Recall: 77.8%)\n",
    "- [Random Forest](#RF) (Accuracy: 88.3% / Precision: 78.1% / Recall: 67.8%)\n",
    "- [Neural Networks](#NN) (Accuracy: 87.3% / Precision: 72.9% / Recall: 70.1%)\n",
    "- [Logistic Regression](#LR) (Accuracy: 84.9% / Precision: 70.7% / Recall: 58.7%)\n",
    "- [Support Vector Machine](#SVM) (Accuracy: 82.8% / Precision: 71.2% / Recall: 42.7%)\n",
    "- [SGD Classifier](#SGD) (Accuracy: 82.5% / Precision: 67.2% / Recall: 46.8%)\n",
    "- [KNN](#KNN) (Accuracy: 78.0% / Precision: 54.5% / Recall: 27.5%)\n",
    "\n",
    "The three models that give the best results are selected for hyperparameter tunings to improve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c24c16",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2272fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8dfaedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    Plot precisions and recalls based on thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(thresholds, precisions[:-1], 'g--', label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], 'y-', label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"center left\")\n",
    "    plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3df85c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f9a70",
   "metadata": {},
   "source": [
    "<a id='XGB'></a>\n",
    "\n",
    "### XGBoost (Accuracy: 90.5% / Precision: 80.1% / Recall: 77.8%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "900022f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold Cross Validation\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(objective= 'binary:logistic', eval_metric='error', use_label_encoder=False)\n",
    "xgb_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "Y_train_pred = cross_val_predict(xgb_cl, X_train_num_cat_scaled, Y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b0f765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9045353413294924\n",
      "Precision:  0.8005754758742807\n",
      "Recall:  0.7785191562634525\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.mean(cross_val_score(xgb_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy')))\n",
    "print(\"Precision: \", precision_score(Y_train, Y_train_pred))\n",
    "print(\"Recall: \", recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afcba19",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6be4f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_child_weight': 3}, 0.9055745077704488)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (1st)\n",
    "# Tune 'max_depth' and 'min_child_weight' with wide steps\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(learning_rate = 0.1, objective= 'binary:logistic', n_estimators = 180, \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_1 = {\n",
    "    'max_depth': range(1, 10, 2),\n",
    "    'min_child_weight' : range(1, 8, 2)\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(estimator = xgb_cl, param_grid = param_1, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_1.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_1.best_params_, grid_search_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "910d609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_child_weight': 2}, 0.9060196727904992)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (2nd)\n",
    "# Tune 'max_depth' and 'min_child_weight' with small steps\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(learning_rate = 0.1, objective= 'binary:logistic', n_estimators = 180, \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_2 = {\n",
    "    'max_depth': [4,5,6],\n",
    "    'min_child_weight' : [2,3,4]\n",
    "}\n",
    "\n",
    "grid_search_2 = GridSearchCV(estimator = xgb_cl, param_grid = param_2, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_2.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_2.best_params_, grid_search_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d9e6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.0}, 0.9060196727904992)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (3rd)\n",
    "# Tune 'gamma' \n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(max_depth = 5, min_child_weight = 2, \n",
    "                           learning_rate = 0.1, objective= 'binary:logistic', n_estimators = 180, \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_3 = {\n",
    "    'gamma' : [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "grid_search_3 = GridSearchCV(estimator = xgb_cl, param_grid = param_3, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_3.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_3.best_params_, grid_search_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97393703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.5, 'subsample': 1.0}, 0.9064153084313953)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (4th)\n",
    "# Tune 'subsample' and 'colsample_bytree'\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(gamma = 0.0, max_depth = 5, min_child_weight = 2, \n",
    "                           learning_rate = 0.1, objective= 'binary:logistic', n_estimators = 180, \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_4 = {\n",
    "    'subsample' : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree' : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_4 = GridSearchCV(estimator = xgb_cl, param_grid = param_4, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_4.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_4.best_params_, grid_search_4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54fab8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.15, 'n_estimators': 180}, 0.9082950395024018)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (5th)\n",
    "# Tune 'subsample' and 'colsample_bytree' \n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(colsample_bytree = 0.5, subsample = 1.0, gamma = 0.0, max_depth = 5, min_child_weight = 2, \n",
    "                           objective= 'binary:logistic',  \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_5 = {\n",
    "    'n_estimators' : [160, 170, 180, 190, 200],\n",
    "    'learning_rate' : [0.01, 0.05, 0.1, 0.15, 0.3]\n",
    "}\n",
    "\n",
    "grid_search_5 = GridSearchCV(estimator = xgb_cl, param_grid = param_5, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_5.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_5.best_params_, grid_search_5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfa3d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.17, 'n_estimators': 170}, 0.9083940615632201)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (6th)\n",
    "# Tune 'subsample' and 'colsample_bytree' \n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(colsample_bytree = 0.5, subsample = 1.0, gamma = 0.0, max_depth = 5, min_child_weight = 2, \n",
    "                           objective= 'binary:logistic',  \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "param_6 = {\n",
    "    'n_estimators' : [170, 175, 180],\n",
    "    'learning_rate' : [0.13, 0.14, 0.15, 0.16, 0.17]\n",
    "}\n",
    "\n",
    "grid_search_6 = GridSearchCV(estimator = xgb_cl, param_grid = param_6, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_6.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_6.best_params_, grid_search_6.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867ad11",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e67aa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold Cross Validation with tuned hyperparameters \n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(learning_rate = 0.17, n_estimators = 170, colsample_bytree = 0.5, \n",
    "                           subsample = 1.0, gamma = 0.0, max_depth = 5, min_child_weight = 2, objective= 'binary:logistic',  \n",
    "                           scale_pos_weight=1, eval_metric='error', use_label_encoder=False)\n",
    "xgb_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "Y_train_pred = cross_val_predict(xgb_cl, X_train_num_cat_scaled, Y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52476ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9082450295634708\n",
      "Precision:  0.8094921268573964\n",
      "Recall:  0.785622040464916\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.mean(cross_val_score(xgb_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy')))\n",
    "print(\"Precision: \", precision_score(Y_train, Y_train_pred))\n",
    "print(\"Recall: \", recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555ad46",
   "metadata": {},
   "source": [
    "Although all metrics (accuracy, precision, and recall) have increased after hyperparameter tuning, it is not a huge improvement. \n",
    "\n",
    "Source: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e4a5e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05307f7",
   "metadata": {},
   "source": [
    "<a id='RF'></a>\n",
    "\n",
    "### Random Forest (Accuracy: 88.3% / Precision: 78.1% / Recall: 67.8%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c4d1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold Cross Validation\n",
    "\n",
    "rnd_cl = RandomForestClassifier(n_estimators=300, max_leaf_nodes=20, n_jobs=-1, oob_score=True, max_features = \"auto\")\n",
    "rnd_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "Y_train_pred = cross_val_predict(rnd_cl, X_train_num_cat_scaled, Y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bbdf6172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8822774811071289\n",
      "Precision:  0.7842551071250623\n",
      "Recall:  0.6775721050365906\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.mean(cross_val_score(rnd_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy')))\n",
    "print(\"Precision: \", precision_score(Y_train, Y_train_pred))\n",
    "print(\"Recall: \", recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8724f9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f722cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 700,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_depth': 50},\n",
       " 0.8960775643044003)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (1st)\n",
    "\n",
    "rnd_cl = RandomForestClassifier(n_jobs=-1, oob_score=True)\n",
    "random_param = {'n_estimators': range(200, 1000, 100),\n",
    "               'max_depth': range(10, 100, 10),\n",
    "               'min_samples_split': range(2,10,1),\n",
    "               'min_samples_leaf': range(1,5,1)}\n",
    "\n",
    "random_search1 = RandomizedSearchCV(estimator = rnd_cl, param_distributions = random_param, \n",
    "                               n_iter = 100, cv = 5, verbose=2, n_jobs = -1)\n",
    "random_search1.fit(X_train_num_cat_scaled, Y_train)\n",
    "random_search1.best_params_, random_search1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b9bc48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 45, 'n_estimators': 670}, 0.8961270936835545)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning (2nd)\n",
    "# Tune 'max_depth' and 'n_estimators' with small steps\n",
    "\n",
    "rnd_cl = RandomForestClassifier(min_samples_split = 2, min_samples_leaf = 1, \n",
    "                                n_jobs=-1, oob_score=True, max_features = \"auto\")\n",
    "\n",
    "param_2 = {\n",
    "    'n_estimators' : range(650, 750, 10),\n",
    "    'max_depth' : [45, 50, 55]\n",
    "}\n",
    "\n",
    "grid_search_2 = GridSearchCV(estimator = rnd_cl, param_grid = param_2, scoring = 'accuracy', n_jobs = -1, cv = 5, verbose=True)\n",
    "grid_search_2.fit(X_train_num_cat_scaled, Y_train)\n",
    "grid_search_2.best_params_, grid_search_2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7cfe21",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e8755ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold Cross Validation with tuned hyperparameters \n",
    "\n",
    "rnd_cl = RandomForestClassifier(max_depth = 45, n_estimators = 670, min_samples_split = 2, min_samples_leaf = 1, \n",
    "                                n_jobs=-1, oob_score=True, max_features = \"auto\")\n",
    "rnd_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "Y_train_pred = cross_val_predict(rnd_cl, X_train_num_cat_scaled, Y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c79e9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8960280800359822\n",
      "Precision:  0.7939267501159017\n",
      "Recall:  0.7371932845458459\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", np.mean(cross_val_score(rnd_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy')))\n",
    "print(\"Precision: \", precision_score(Y_train, Y_train_pred))\n",
    "print(\"Recall: \", recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283a864",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e9018",
   "metadata": {},
   "source": [
    "<a id='NN'></a>\n",
    "\n",
    "### Neural Networks (Accuracy: 87.3% / Precision: 72.9% / Recall: 70.1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c796057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_test_num_cat.shape[1]\n",
    "\n",
    "def create_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d5d9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8748570523841896"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = KerasClassifier(build_fn=create_network, \n",
    "                                 epochs=100, \n",
    "                                 batch_size=32, \n",
    "                                 verbose=0)\n",
    "\n",
    "np.mean(cross_val_score(neural_network, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7058c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7420918956361118 0.6917778734395179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = cross_val_predict(neural_network, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab753590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "632/632 [==============================] - 1s 477us/step - loss: 0.5072 - accuracy: 0.7616\n",
      "Epoch 2/200\n",
      "632/632 [==============================] - 0s 488us/step - loss: 0.3815 - accuracy: 0.8247\n",
      "Epoch 3/200\n",
      "632/632 [==============================] - 0s 489us/step - loss: 0.3630 - accuracy: 0.8380\n",
      "Epoch 4/200\n",
      "632/632 [==============================] - 0s 564us/step - loss: 0.3528 - accuracy: 0.8435\n",
      "Epoch 5/200\n",
      "632/632 [==============================] - 0s 586us/step - loss: 0.3440 - accuracy: 0.8449\n",
      "Epoch 6/200\n",
      "632/632 [==============================] - 0s 591us/step - loss: 0.3344 - accuracy: 0.8467\n",
      "Epoch 7/200\n",
      "632/632 [==============================] - 0s 560us/step - loss: 0.3261 - accuracy: 0.8503\n",
      "Epoch 8/200\n",
      "632/632 [==============================] - 0s 602us/step - loss: 0.3173 - accuracy: 0.8556\n",
      "Epoch 9/200\n",
      "632/632 [==============================] - 0s 605us/step - loss: 0.3096 - accuracy: 0.8595\n",
      "Epoch 10/200\n",
      "632/632 [==============================] - 0s 564us/step - loss: 0.3060 - accuracy: 0.8612\n",
      "Epoch 11/200\n",
      "632/632 [==============================] - 0s 570us/step - loss: 0.3007 - accuracy: 0.8630\n",
      "Epoch 12/200\n",
      "632/632 [==============================] - 0s 637us/step - loss: 0.2962 - accuracy: 0.8664\n",
      "Epoch 13/200\n",
      "632/632 [==============================] - 0s 605us/step - loss: 0.2946 - accuracy: 0.8655\n",
      "Epoch 14/200\n",
      "632/632 [==============================] - 0s 562us/step - loss: 0.2929 - accuracy: 0.8675\n",
      "Epoch 15/200\n",
      "632/632 [==============================] - 0s 581us/step - loss: 0.2904 - accuracy: 0.8689\n",
      "Epoch 16/200\n",
      "632/632 [==============================] - 0s 609us/step - loss: 0.2888 - accuracy: 0.8711\n",
      "Epoch 17/200\n",
      "632/632 [==============================] - 0s 620us/step - loss: 0.2889 - accuracy: 0.8684\n",
      "Epoch 18/200\n",
      "632/632 [==============================] - 0s 589us/step - loss: 0.2871 - accuracy: 0.8685\n",
      "Epoch 19/200\n",
      "632/632 [==============================] - 0s 593us/step - loss: 0.2863 - accuracy: 0.8710\n",
      "Epoch 20/200\n",
      "632/632 [==============================] - 0s 563us/step - loss: 0.2840 - accuracy: 0.8721\n",
      "Epoch 21/200\n",
      "632/632 [==============================] - 0s 573us/step - loss: 0.2830 - accuracy: 0.8723\n",
      "Epoch 22/200\n",
      "632/632 [==============================] - 0s 621us/step - loss: 0.2842 - accuracy: 0.8723\n",
      "Epoch 23/200\n",
      "632/632 [==============================] - 0s 672us/step - loss: 0.2814 - accuracy: 0.8733\n",
      "Epoch 24/200\n",
      "632/632 [==============================] - 0s 610us/step - loss: 0.2812 - accuracy: 0.8727\n",
      "Epoch 25/200\n",
      "632/632 [==============================] - 0s 623us/step - loss: 0.2790 - accuracy: 0.8746\n",
      "Epoch 26/200\n",
      "632/632 [==============================] - 0s 590us/step - loss: 0.2792 - accuracy: 0.8758\n",
      "Epoch 27/200\n",
      "632/632 [==============================] - 0s 530us/step - loss: 0.2797 - accuracy: 0.8733\n",
      "Epoch 28/200\n",
      "632/632 [==============================] - 0s 584us/step - loss: 0.2773 - accuracy: 0.8754\n",
      "Epoch 29/200\n",
      "632/632 [==============================] - 0s 574us/step - loss: 0.2774 - accuracy: 0.8764\n",
      "Epoch 30/200\n",
      "632/632 [==============================] - 0s 594us/step - loss: 0.2759 - accuracy: 0.8755\n",
      "Epoch 31/200\n",
      "632/632 [==============================] - 0s 545us/step - loss: 0.2761 - accuracy: 0.8758\n",
      "Epoch 32/200\n",
      "632/632 [==============================] - 0s 562us/step - loss: 0.2747 - accuracy: 0.8776\n",
      "Epoch 33/200\n",
      "632/632 [==============================] - 0s 621us/step - loss: 0.2745 - accuracy: 0.8772\n",
      "Epoch 34/200\n",
      "632/632 [==============================] - 0s 600us/step - loss: 0.2730 - accuracy: 0.8774\n",
      "Epoch 35/200\n",
      "632/632 [==============================] - 0s 603us/step - loss: 0.2714 - accuracy: 0.8790\n",
      "Epoch 36/200\n",
      "632/632 [==============================] - 0s 557us/step - loss: 0.2720 - accuracy: 0.8780\n",
      "Epoch 37/200\n",
      "632/632 [==============================] - 0s 552us/step - loss: 0.2725 - accuracy: 0.8766\n",
      "Epoch 38/200\n",
      "632/632 [==============================] - 0s 624us/step - loss: 0.2710 - accuracy: 0.8783\n",
      "Epoch 39/200\n",
      "632/632 [==============================] - 0s 594us/step - loss: 0.2712 - accuracy: 0.8778\n",
      "Epoch 40/200\n",
      "632/632 [==============================] - 0s 569us/step - loss: 0.2709 - accuracy: 0.8754\n",
      "Epoch 41/200\n",
      "632/632 [==============================] - 0s 575us/step - loss: 0.2708 - accuracy: 0.8769\n",
      "Epoch 42/200\n",
      "632/632 [==============================] - 0s 576us/step - loss: 0.2692 - accuracy: 0.8784\n",
      "Epoch 43/200\n",
      "632/632 [==============================] - 0s 574us/step - loss: 0.2689 - accuracy: 0.8789\n",
      "Epoch 44/200\n",
      "632/632 [==============================] - 0s 618us/step - loss: 0.2667 - accuracy: 0.8803\n",
      "Epoch 45/200\n",
      "632/632 [==============================] - 0s 565us/step - loss: 0.2673 - accuracy: 0.8795\n",
      "Epoch 46/200\n",
      "632/632 [==============================] - 0s 550us/step - loss: 0.2668 - accuracy: 0.8811\n",
      "Epoch 47/200\n",
      "632/632 [==============================] - 0s 771us/step - loss: 0.2661 - accuracy: 0.8807\n",
      "Epoch 48/200\n",
      "632/632 [==============================] - 0s 712us/step - loss: 0.2670 - accuracy: 0.8793\n",
      "Epoch 49/200\n",
      "632/632 [==============================] - 0s 682us/step - loss: 0.2657 - accuracy: 0.8810\n",
      "Epoch 50/200\n",
      "632/632 [==============================] - 0s 595us/step - loss: 0.2648 - accuracy: 0.8816\n",
      "Epoch 51/200\n",
      "632/632 [==============================] - 1s 840us/step - loss: 0.2649 - accuracy: 0.8805\n",
      "Epoch 52/200\n",
      "632/632 [==============================] - 0s 762us/step - loss: 0.2662 - accuracy: 0.8811\n",
      "Epoch 53/200\n",
      "632/632 [==============================] - 0s 630us/step - loss: 0.2647 - accuracy: 0.8823\n",
      "Epoch 54/200\n",
      "632/632 [==============================] - 0s 775us/step - loss: 0.2642 - accuracy: 0.8830\n",
      "Epoch 55/200\n",
      "632/632 [==============================] - 0s 603us/step - loss: 0.2644 - accuracy: 0.8820\n",
      "Epoch 56/200\n",
      "632/632 [==============================] - 0s 582us/step - loss: 0.2645 - accuracy: 0.8805\n",
      "Epoch 57/200\n",
      "632/632 [==============================] - 0s 593us/step - loss: 0.2624 - accuracy: 0.8834\n",
      "Epoch 58/200\n",
      "632/632 [==============================] - 0s 738us/step - loss: 0.2624 - accuracy: 0.8828\n",
      "Epoch 59/200\n",
      "632/632 [==============================] - 0s 776us/step - loss: 0.2637 - accuracy: 0.8817\n",
      "Epoch 60/200\n",
      "632/632 [==============================] - 0s 718us/step - loss: 0.2629 - accuracy: 0.8828\n",
      "Epoch 61/200\n",
      "632/632 [==============================] - 1s 798us/step - loss: 0.2627 - accuracy: 0.8815\n",
      "Epoch 62/200\n",
      "632/632 [==============================] - 0s 640us/step - loss: 0.2622 - accuracy: 0.8820\n",
      "Epoch 63/200\n",
      "632/632 [==============================] - 0s 550us/step - loss: 0.2605 - accuracy: 0.8845\n",
      "Epoch 64/200\n",
      "632/632 [==============================] - 0s 543us/step - loss: 0.2604 - accuracy: 0.8838\n",
      "Epoch 65/200\n",
      "632/632 [==============================] - 0s 548us/step - loss: 0.2600 - accuracy: 0.8837\n",
      "Epoch 66/200\n",
      "632/632 [==============================] - 0s 522us/step - loss: 0.2619 - accuracy: 0.8821\n",
      "Epoch 67/200\n",
      "632/632 [==============================] - 0s 558us/step - loss: 0.2601 - accuracy: 0.8826\n",
      "Epoch 68/200\n",
      "632/632 [==============================] - 0s 563us/step - loss: 0.2603 - accuracy: 0.8840\n",
      "Epoch 69/200\n",
      "632/632 [==============================] - 0s 628us/step - loss: 0.2596 - accuracy: 0.8828\n",
      "Epoch 70/200\n",
      "632/632 [==============================] - 0s 536us/step - loss: 0.2583 - accuracy: 0.8854\n",
      "Epoch 71/200\n",
      "632/632 [==============================] - 0s 577us/step - loss: 0.2589 - accuracy: 0.8840\n",
      "Epoch 72/200\n",
      "632/632 [==============================] - 0s 557us/step - loss: 0.2594 - accuracy: 0.8841\n",
      "Epoch 73/200\n",
      "632/632 [==============================] - 0s 559us/step - loss: 0.2574 - accuracy: 0.8843\n",
      "Epoch 74/200\n",
      "632/632 [==============================] - 0s 526us/step - loss: 0.2591 - accuracy: 0.8833\n",
      "Epoch 75/200\n",
      "632/632 [==============================] - 0s 539us/step - loss: 0.2594 - accuracy: 0.8854\n",
      "Epoch 76/200\n",
      "632/632 [==============================] - 0s 545us/step - loss: 0.2576 - accuracy: 0.8853\n",
      "Epoch 77/200\n",
      "632/632 [==============================] - 0s 552us/step - loss: 0.2581 - accuracy: 0.8851\n",
      "Epoch 78/200\n",
      "632/632 [==============================] - 0s 534us/step - loss: 0.2555 - accuracy: 0.8866\n",
      "Epoch 79/200\n",
      "632/632 [==============================] - 0s 554us/step - loss: 0.2571 - accuracy: 0.8831\n",
      "Epoch 80/200\n",
      "632/632 [==============================] - 0s 567us/step - loss: 0.2560 - accuracy: 0.8845\n",
      "Epoch 81/200\n",
      "632/632 [==============================] - 0s 538us/step - loss: 0.2566 - accuracy: 0.8832\n",
      "Epoch 82/200\n",
      "632/632 [==============================] - 0s 561us/step - loss: 0.2554 - accuracy: 0.8857\n",
      "Epoch 83/200\n",
      "632/632 [==============================] - 0s 554us/step - loss: 0.2554 - accuracy: 0.8863\n",
      "Epoch 84/200\n",
      "632/632 [==============================] - 0s 530us/step - loss: 0.2557 - accuracy: 0.8865\n",
      "Epoch 85/200\n",
      "632/632 [==============================] - 0s 530us/step - loss: 0.2551 - accuracy: 0.8871\n",
      "Epoch 86/200\n",
      "632/632 [==============================] - 0s 551us/step - loss: 0.2537 - accuracy: 0.8845\n",
      "Epoch 87/200\n",
      "632/632 [==============================] - 0s 555us/step - loss: 0.2546 - accuracy: 0.8869\n",
      "Epoch 88/200\n",
      "632/632 [==============================] - 0s 534us/step - loss: 0.2547 - accuracy: 0.8859\n",
      "Epoch 89/200\n",
      "632/632 [==============================] - 0s 551us/step - loss: 0.2543 - accuracy: 0.8860\n",
      "Epoch 90/200\n",
      "632/632 [==============================] - 0s 521us/step - loss: 0.2528 - accuracy: 0.8847\n",
      "Epoch 91/200\n",
      "632/632 [==============================] - 0s 532us/step - loss: 0.2536 - accuracy: 0.8846\n",
      "Epoch 92/200\n",
      "632/632 [==============================] - 0s 541us/step - loss: 0.2548 - accuracy: 0.8845\n",
      "Epoch 93/200\n",
      "632/632 [==============================] - 0s 546us/step - loss: 0.2534 - accuracy: 0.8869\n",
      "Epoch 94/200\n",
      "632/632 [==============================] - 0s 537us/step - loss: 0.2539 - accuracy: 0.8864\n",
      "Epoch 95/200\n",
      "632/632 [==============================] - 0s 648us/step - loss: 0.2538 - accuracy: 0.8867\n",
      "Epoch 96/200\n",
      "632/632 [==============================] - 0s 555us/step - loss: 0.2522 - accuracy: 0.8856\n",
      "Epoch 97/200\n",
      "632/632 [==============================] - 0s 548us/step - loss: 0.2539 - accuracy: 0.8857\n",
      "Epoch 98/200\n",
      "632/632 [==============================] - 0s 536us/step - loss: 0.2530 - accuracy: 0.8877\n",
      "Epoch 99/200\n",
      "632/632 [==============================] - 0s 588us/step - loss: 0.2525 - accuracy: 0.8850\n",
      "Epoch 100/200\n",
      "632/632 [==============================] - 0s 560us/step - loss: 0.2518 - accuracy: 0.8876\n",
      "Epoch 101/200\n",
      "632/632 [==============================] - 0s 541us/step - loss: 0.2509 - accuracy: 0.8878\n",
      "Epoch 102/200\n",
      "632/632 [==============================] - 0s 556us/step - loss: 0.2504 - accuracy: 0.8860\n",
      "Epoch 103/200\n",
      "632/632 [==============================] - 0s 531us/step - loss: 0.2511 - accuracy: 0.8867\n",
      "Epoch 104/200\n",
      "632/632 [==============================] - 0s 587us/step - loss: 0.2521 - accuracy: 0.8875\n",
      "Epoch 105/200\n",
      "632/632 [==============================] - 0s 521us/step - loss: 0.2496 - accuracy: 0.8876\n",
      "Epoch 106/200\n",
      "632/632 [==============================] - 0s 539us/step - loss: 0.2505 - accuracy: 0.8875\n",
      "Epoch 107/200\n",
      "632/632 [==============================] - 0s 565us/step - loss: 0.2491 - accuracy: 0.8878\n",
      "Epoch 108/200\n",
      "632/632 [==============================] - 0s 615us/step - loss: 0.2502 - accuracy: 0.8864\n",
      "Epoch 109/200\n",
      "632/632 [==============================] - 0s 595us/step - loss: 0.2491 - accuracy: 0.8862\n",
      "Epoch 110/200\n",
      "632/632 [==============================] - 0s 585us/step - loss: 0.2498 - accuracy: 0.8889\n",
      "Epoch 111/200\n",
      "632/632 [==============================] - 0s 558us/step - loss: 0.2513 - accuracy: 0.8881\n",
      "Epoch 112/200\n",
      "632/632 [==============================] - 0s 520us/step - loss: 0.2494 - accuracy: 0.8880\n",
      "Epoch 113/200\n",
      "632/632 [==============================] - 0s 523us/step - loss: 0.2503 - accuracy: 0.8875\n",
      "Epoch 114/200\n",
      "632/632 [==============================] - 0s 563us/step - loss: 0.2476 - accuracy: 0.8869\n",
      "Epoch 115/200\n",
      "632/632 [==============================] - 0s 649us/step - loss: 0.2493 - accuracy: 0.8885\n",
      "Epoch 116/200\n",
      "632/632 [==============================] - 0s 624us/step - loss: 0.2488 - accuracy: 0.8882\n",
      "Epoch 117/200\n",
      "632/632 [==============================] - 0s 570us/step - loss: 0.2471 - accuracy: 0.8884\n",
      "Epoch 118/200\n",
      "632/632 [==============================] - 0s 582us/step - loss: 0.2482 - accuracy: 0.8884\n",
      "Epoch 119/200\n",
      "632/632 [==============================] - 0s 678us/step - loss: 0.2486 - accuracy: 0.8870\n",
      "Epoch 120/200\n",
      "632/632 [==============================] - 0s 602us/step - loss: 0.2473 - accuracy: 0.8879\n",
      "Epoch 121/200\n",
      "632/632 [==============================] - 0s 638us/step - loss: 0.2470 - accuracy: 0.8876\n",
      "Epoch 122/200\n",
      "632/632 [==============================] - 0s 517us/step - loss: 0.2481 - accuracy: 0.8880\n",
      "Epoch 123/200\n",
      "632/632 [==============================] - 0s 521us/step - loss: 0.2469 - accuracy: 0.8894\n",
      "Epoch 124/200\n",
      "632/632 [==============================] - 0s 596us/step - loss: 0.2454 - accuracy: 0.8903\n",
      "Epoch 125/200\n",
      "632/632 [==============================] - 0s 621us/step - loss: 0.2471 - accuracy: 0.8892\n",
      "Epoch 126/200\n",
      "632/632 [==============================] - 0s 662us/step - loss: 0.2459 - accuracy: 0.8901\n",
      "Epoch 127/200\n",
      "632/632 [==============================] - 0s 669us/step - loss: 0.2457 - accuracy: 0.8890\n",
      "Epoch 128/200\n",
      "632/632 [==============================] - 0s 611us/step - loss: 0.2468 - accuracy: 0.8900\n",
      "Epoch 129/200\n",
      "632/632 [==============================] - 0s 708us/step - loss: 0.2457 - accuracy: 0.8887\n",
      "Epoch 130/200\n",
      "632/632 [==============================] - 0s 593us/step - loss: 0.2454 - accuracy: 0.8904\n",
      "Epoch 131/200\n",
      "632/632 [==============================] - 0s 591us/step - loss: 0.2445 - accuracy: 0.8903\n",
      "Epoch 132/200\n",
      "632/632 [==============================] - 0s 575us/step - loss: 0.2460 - accuracy: 0.8901\n",
      "Epoch 133/200\n",
      "632/632 [==============================] - 0s 532us/step - loss: 0.2442 - accuracy: 0.8902\n",
      "Epoch 134/200\n",
      "632/632 [==============================] - 0s 524us/step - loss: 0.2449 - accuracy: 0.8904\n",
      "Epoch 135/200\n",
      "632/632 [==============================] - 0s 570us/step - loss: 0.2450 - accuracy: 0.8887\n",
      "Epoch 136/200\n",
      "632/632 [==============================] - 0s 523us/step - loss: 0.2436 - accuracy: 0.8908\n",
      "Epoch 137/200\n",
      "632/632 [==============================] - 0s 630us/step - loss: 0.2442 - accuracy: 0.8917\n",
      "Epoch 138/200\n",
      "632/632 [==============================] - 0s 656us/step - loss: 0.2425 - accuracy: 0.8925\n",
      "Epoch 139/200\n",
      "632/632 [==============================] - 0s 592us/step - loss: 0.2450 - accuracy: 0.8901\n",
      "Epoch 140/200\n",
      "632/632 [==============================] - 0s 551us/step - loss: 0.2464 - accuracy: 0.8896\n",
      "Epoch 141/200\n",
      "632/632 [==============================] - 0s 602us/step - loss: 0.2425 - accuracy: 0.8922\n",
      "Epoch 142/200\n",
      "632/632 [==============================] - 0s 559us/step - loss: 0.2434 - accuracy: 0.8900\n",
      "Epoch 143/200\n",
      "632/632 [==============================] - 0s 547us/step - loss: 0.2427 - accuracy: 0.8907\n",
      "Epoch 144/200\n",
      "632/632 [==============================] - 0s 588us/step - loss: 0.2422 - accuracy: 0.8913\n",
      "Epoch 145/200\n",
      "632/632 [==============================] - 0s 581us/step - loss: 0.2435 - accuracy: 0.8892\n",
      "Epoch 146/200\n",
      "632/632 [==============================] - 0s 558us/step - loss: 0.2428 - accuracy: 0.8924\n",
      "Epoch 147/200\n",
      "632/632 [==============================] - 0s 630us/step - loss: 0.2419 - accuracy: 0.8919\n",
      "Epoch 148/200\n",
      "632/632 [==============================] - 0s 551us/step - loss: 0.2423 - accuracy: 0.8912\n",
      "Epoch 149/200\n",
      "632/632 [==============================] - 0s 557us/step - loss: 0.2424 - accuracy: 0.8918\n",
      "Epoch 150/200\n",
      "632/632 [==============================] - 0s 630us/step - loss: 0.2421 - accuracy: 0.8920\n",
      "Epoch 151/200\n",
      "632/632 [==============================] - 0s 592us/step - loss: 0.2417 - accuracy: 0.8928\n",
      "Epoch 152/200\n",
      "632/632 [==============================] - 0s 588us/step - loss: 0.2421 - accuracy: 0.8912\n",
      "Epoch 153/200\n",
      "632/632 [==============================] - 0s 617us/step - loss: 0.2407 - accuracy: 0.8904\n",
      "Epoch 154/200\n",
      "632/632 [==============================] - 0s 589us/step - loss: 0.2408 - accuracy: 0.8927\n",
      "Epoch 155/200\n",
      "632/632 [==============================] - 0s 560us/step - loss: 0.2411 - accuracy: 0.8939\n",
      "Epoch 156/200\n",
      "632/632 [==============================] - 0s 524us/step - loss: 0.2402 - accuracy: 0.8930\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/632 [==============================] - 0s 558us/step - loss: 0.2406 - accuracy: 0.8935\n",
      "Epoch 158/200\n",
      "632/632 [==============================] - 0s 557us/step - loss: 0.2417 - accuracy: 0.8904\n",
      "Epoch 159/200\n",
      "632/632 [==============================] - 0s 575us/step - loss: 0.2409 - accuracy: 0.8927\n",
      "Epoch 160/200\n",
      "632/632 [==============================] - 0s 621us/step - loss: 0.2395 - accuracy: 0.8938\n",
      "Epoch 161/200\n",
      "632/632 [==============================] - 0s 590us/step - loss: 0.2404 - accuracy: 0.8933\n",
      "Epoch 162/200\n",
      "632/632 [==============================] - 0s 542us/step - loss: 0.2400 - accuracy: 0.8914\n",
      "Epoch 163/200\n",
      "632/632 [==============================] - 0s 549us/step - loss: 0.2395 - accuracy: 0.8926\n",
      "Epoch 164/200\n",
      "632/632 [==============================] - 0s 546us/step - loss: 0.2400 - accuracy: 0.8917\n",
      "Epoch 165/200\n",
      "632/632 [==============================] - 0s 606us/step - loss: 0.2388 - accuracy: 0.8930\n",
      "Epoch 166/200\n",
      "632/632 [==============================] - 0s 539us/step - loss: 0.2407 - accuracy: 0.8925\n",
      "Epoch 167/200\n",
      "632/632 [==============================] - 0s 538us/step - loss: 0.2384 - accuracy: 0.8939\n",
      "Epoch 168/200\n",
      "632/632 [==============================] - 0s 598us/step - loss: 0.2388 - accuracy: 0.8937\n",
      "Epoch 169/200\n",
      "632/632 [==============================] - 0s 565us/step - loss: 0.2388 - accuracy: 0.8939\n",
      "Epoch 170/200\n",
      "632/632 [==============================] - 0s 525us/step - loss: 0.2419 - accuracy: 0.8925\n",
      "Epoch 171/200\n",
      "632/632 [==============================] - 0s 593us/step - loss: 0.2380 - accuracy: 0.8966\n",
      "Epoch 172/200\n",
      "632/632 [==============================] - 0s 624us/step - loss: 0.2388 - accuracy: 0.8926\n",
      "Epoch 173/200\n",
      "632/632 [==============================] - 0s 574us/step - loss: 0.2380 - accuracy: 0.8936\n",
      "Epoch 174/200\n",
      "632/632 [==============================] - 0s 562us/step - loss: 0.2388 - accuracy: 0.8936\n",
      "Epoch 175/200\n",
      "632/632 [==============================] - 0s 616us/step - loss: 0.2395 - accuracy: 0.8923\n",
      "Epoch 176/200\n",
      "632/632 [==============================] - 0s 554us/step - loss: 0.2388 - accuracy: 0.8945\n",
      "Epoch 177/200\n",
      "632/632 [==============================] - 0s 562us/step - loss: 0.2377 - accuracy: 0.8934\n",
      "Epoch 178/200\n",
      "632/632 [==============================] - 0s 575us/step - loss: 0.2379 - accuracy: 0.8929\n",
      "Epoch 179/200\n",
      "632/632 [==============================] - 0s 554us/step - loss: 0.2381 - accuracy: 0.8960\n",
      "Epoch 180/200\n",
      "632/632 [==============================] - 0s 570us/step - loss: 0.2357 - accuracy: 0.8958\n",
      "Epoch 181/200\n",
      "632/632 [==============================] - 0s 572us/step - loss: 0.2378 - accuracy: 0.8931\n",
      "Epoch 182/200\n",
      "632/632 [==============================] - 0s 556us/step - loss: 0.2372 - accuracy: 0.8940\n",
      "Epoch 183/200\n",
      "632/632 [==============================] - 0s 545us/step - loss: 0.2378 - accuracy: 0.8937\n",
      "Epoch 184/200\n",
      "632/632 [==============================] - 0s 600us/step - loss: 0.2371 - accuracy: 0.8931\n",
      "Epoch 185/200\n",
      "632/632 [==============================] - 0s 599us/step - loss: 0.2369 - accuracy: 0.8942\n",
      "Epoch 186/200\n",
      "632/632 [==============================] - 0s 590us/step - loss: 0.2371 - accuracy: 0.8942\n",
      "Epoch 187/200\n",
      "632/632 [==============================] - 0s 523us/step - loss: 0.2377 - accuracy: 0.8935\n",
      "Epoch 188/200\n",
      "632/632 [==============================] - 0s 558us/step - loss: 0.2366 - accuracy: 0.8944\n",
      "Epoch 189/200\n",
      "632/632 [==============================] - 0s 571us/step - loss: 0.2358 - accuracy: 0.8929\n",
      "Epoch 190/200\n",
      "632/632 [==============================] - 0s 551us/step - loss: 0.2360 - accuracy: 0.8953\n",
      "Epoch 191/200\n",
      "632/632 [==============================] - 0s 618us/step - loss: 0.2382 - accuracy: 0.8933\n",
      "Epoch 192/200\n",
      "632/632 [==============================] - 0s 609us/step - loss: 0.2390 - accuracy: 0.8926\n",
      "Epoch 193/200\n",
      "632/632 [==============================] - 0s 578us/step - loss: 0.2367 - accuracy: 0.8941\n",
      "Epoch 194/200\n",
      "632/632 [==============================] - 0s 555us/step - loss: 0.2343 - accuracy: 0.8943\n",
      "Epoch 195/200\n",
      "632/632 [==============================] - 0s 569us/step - loss: 0.2354 - accuracy: 0.8942\n",
      "Epoch 196/200\n",
      "632/632 [==============================] - 0s 557us/step - loss: 0.2368 - accuracy: 0.8910\n",
      "Epoch 197/200\n",
      "632/632 [==============================] - 0s 581us/step - loss: 0.2352 - accuracy: 0.8946\n",
      "Epoch 198/200\n",
      "632/632 [==============================] - 0s 542us/step - loss: 0.2344 - accuracy: 0.8947\n",
      "Epoch 199/200\n",
      "632/632 [==============================] - 0s 701us/step - loss: 0.2357 - accuracy: 0.8952\n",
      "Epoch 200/200\n",
      "632/632 [==============================] - 0s 597us/step - loss: 0.2344 - accuracy: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x239824fac40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train_num_cat_scaled, Y_train, epochs=200, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d701443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_features = X_test_num_cat_scaled.shape[1]\\nmodel = Sequential()\\nmodel.add(Dense(20, activation=\\'relu\\', kernel_initializer=\\'he_normal\\', input_shape=(n_features,)))\\nmodel.add(Dense(10, activation=\\'relu\\', kernel_initializer=\\'he_normal\\'))\\nmodel.add(Dense(8, activation=\\'relu\\', kernel_initializer=\\'he_normal\\'))\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\n# compile the model\\nmodel.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\', metrics=[\\'accuracy\\'])\\n# fit the model\\nmodel.fit(X_train_num_cat_scaled, Y_train, epochs=200, batch_size=32, verbose=1)\\n\\nprint(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test_num_cat_scaled, Y_test)))\\n\\n\\n# evaluate the model\\n#loss, acc = model.evaluate(X_test, Y_test, verbose=0)\\n#print(\\'Test Accuracy: %.3f\\' % acc)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"n_features = X_test_num_cat_scaled.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train_num_cat_scaled, Y_train, epochs=200, batch_size=32, verbose=1)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test_num_cat_scaled, Y_test)))\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "#loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "#print('Test Accuracy: %.3f' % acc)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8ac73",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac7968",
   "metadata": {},
   "source": [
    "<a id='LR'></a>\n",
    "\n",
    "### Logistic Regression CV (Accuracy: 84.9% / Precision: 70.7% / Recall: 58.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8aad9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493349259090138"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold Cross Validation\n",
    "\n",
    "log_cl = LogisticRegression(solver=\"lbfgs\", C=10, max_iter=400, random_state=0)\n",
    "log_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "np.mean(cross_val_score(log_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208b6d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7074688796680498 0.5871717606543263\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = cross_val_predict(log_cl, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2acc42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision vs. Recall based on thresholds\n",
    "\n",
    "Y_log_scores = cross_val_predict(log_cl, X_train_num_cat_scaled, Y_train, cv=10, method='decision_function')\n",
    "precisions_log, recalls_log, thresholds_log = precision_recall_curve(Y_train, Y_log_scores)\n",
    "prec_rec_threshold(precisions_log, recalls_log, thresholds_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d8d2dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST (SCALED)\\n\\nsoftmax_reg = LogisticRegression(solver=\"lbfgs\", C=10, max_iter=3000, random_state=0)\\nsoftmax_reg.fit(X_train_num_cat_scaled, Y_train)\\n\\nprint(softmax_reg.score(X_train_num_cat_scaled, Y_train))   # train error\\nprint(softmax_reg.score(X_test_num_cat_scaled, Y_test))     # test error\\n\\npredictions = softmax_reg.predict(X_test_num_cat_scaled)\\nprint(classification_report(Y_test, predictions))\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TEST (SCALED)\n",
    "\n",
    "softmax_reg = LogisticRegression(solver=\"lbfgs\", C=10, max_iter=3000, random_state=0)\n",
    "softmax_reg.fit(X_train_num_cat_scaled, Y_train)\n",
    "\n",
    "print(softmax_reg.score(X_train_num_cat_scaled, Y_train))   # train error\n",
    "print(softmax_reg.score(X_test_num_cat_scaled, Y_test))     # test error\n",
    "\n",
    "predictions = softmax_reg.predict(X_test_num_cat_scaled)\n",
    "print(classification_report(Y_test, predictions))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d4d6e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Grid search / TEST (SCALED)\\n\\n\\nfrom sklearn.model_selection import GridSearchCV\\n\\n\\nparams = {'C':[1, 5, 10, 15, 50, 100], 'tol': [0.001, 0.0001, 0.005]}\\nlog_reg = LogisticRegression(solver='lbfgs', max_iter=500, penalty='l2')\\nclf = GridSearchCV(log_reg, params, refit='True', n_jobs=1, verbose=3, cv=5)\\nclf.fit(X_train, Y_train)\\n\\nprint(clf.score(X_train, Y_train))   # train error\\nprint(clf.score(X_test, Y_test))     # test error\\n\\npredictions = clf.predict(X_test)\\nprint(classification_report(Y_test, predictions))\\n\\nprint(clf.best_params_)\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Grid search / TEST (SCALED)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {'C':[1, 5, 10, 15, 50, 100], 'tol': [0.001, 0.0001, 0.005]}\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=500, penalty='l2')\n",
    "clf = GridSearchCV(log_reg, params, refit='True', n_jobs=1, verbose=3, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.score(X_train, Y_train))   # train error\n",
    "print(clf.score(X_test, Y_test))     # test error\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(Y_test, predictions))\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701feb4",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a1bbe",
   "metadata": {},
   "source": [
    "<a id='SVM'></a>\n",
    "\n",
    "### Support Vector Machine (Accuracy: 82.8% / Precision: 71.2% / Recall: 42.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ca7d1",
   "metadata": {},
   "source": [
    "- When the SVM model is overfitting, we can decrease C (the lower the C, the wider the margin and the larger the margin violation or error) to control the model. \n",
    "\n",
    "- 사실 대부분의 마진 오류 (margin violation - 즉, 샘플이 도로 중간이나 심지어 반대쪽에 있는 경우)은 결정 경계를 기준으로 올바른 클래스로 분류되기 때문에 보통 훈련 세트에서 예측 에러는 마진 오류보다 작다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a3c28",
   "metadata": {},
   "source": [
    "- 다항식 특성을 추가하는 것은 간단하고 (SVM 뿐만 아니라) 모든 머신러닝 알고리즘에서 잘 작동합니다. 하지만 낮은차수의 다항식은 매우 복잡한 데이터셋을 잘 표현하지 못하고 높은 차수의 다항식은 굉장히 많은 특성을 추가하므로 모델을 느리게 만듭니다. \n",
    "\n",
    "- 다행히도 SVM 을 사용할 땐 kernel trick 이라는 거의 기적에 가까운 수학적 기교를 적용할 수 있습니다. 실제로는 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것과 같은 결과 얻을 수 있습니다. => 사실 어떤 특성도 추가하지 않기 때문에 엄청난 수의 특성 조합이 생기지 않습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80a11e",
   "metadata": {},
   "source": [
    "- coef0: 모델이 높은 차수와 낮은 차수에 얼마나 영향을 받을지 조절 (기본값: 0)\n",
    "\n",
    "    - 다항식 커널은 차수가 높아질수록 1보다 작은 값과 1보다 큰 값의 차이가 크게 벌이지므로 coef0을 적절한 값으로 지정하면 고차항의 영향을 줄일 수 있음. \n",
    "    \n",
    "- gamma: gamma를 증가시키면 종 모양 그래프가 좁아져서 각 샘플의 영향 범위가 작아짐. 결정경계가 조금 더 불규칙해지고 각 샘플을 따라 구불구불하게 휘어짐. 작은 gamma 값은 종 모양 그래프를 만들며 샘플이 넓은 범위에 걸쳐 영향을 주므로 결정 경계가 더 부드러워짐\n",
    "    - 결국 하이퍼파라미터 gamma가 규제의 역할을 함. 모델이 과대적합을 경우엔 감소시켜야 하고 과소적합일 경우엔 증가시켜야 함 (C와 비슷)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84f2d5",
   "metadata": {},
   "source": [
    "- 여러 가지 커널 중 어떤 것을 사용해야 할까? 경험적으로 봤을 때 언제나 선형 커널을 가장 먼저 시도해봐야됨. (LinearSVC가 SVC(kernel=\"linear\") 보다 훨씬 빠름을 기억). 특히 훈련 세트가 아주 크거나 특성 수가 많을 때 더욱 그럼. 훈련 세트가 너무 크지 않다면 가우시안 rfb 커널을 시도해보면 좋음. 대부분의 경우 이 커널이 잘 들어맞음. 시간과 컴퓨팅 성능이 충분하다면 (특히 훈련 데이터의 구조에 특화된 커널이 있는 경우) 교차 검증과 그리드 탐색을 사용해 다른 커널을 좀 더 시도해볼 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3eff4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285104816831772"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold Cross validation\n",
    "\n",
    "svm_cl=SVC(random_state=1, coef0=0, C=1, gamma= 'scale', kernel='rbf', decision_function_shape='ovo')\n",
    "svm_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "np.mean(cross_val_score(svm_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b732c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711669658886894 0.4266035299182092\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = cross_val_predict(svm_cl, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eff305a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision vs. Recall based on thresholds\n",
    "\n",
    "Y_svm_scores = cross_val_predict(svm_cl, X_train_num_cat_scaled, Y_train, cv=10, method='decision_function')\n",
    "precisions_svm, recalls_svm, thresholds_svm = precision_recall_curve(Y_train, Y_svm_scores)\n",
    "prec_rec_threshold(precisions_svm, recalls_svm, thresholds_svm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440dcef",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ade52",
   "metadata": {},
   "source": [
    "<a id='SGD'></a>\n",
    "\n",
    "### SGD Classifier (Accuracy: 82.5% / Precision: 67.2% / Recall: 46.8%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f26fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251976159328045"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_cl = SGDClassifier(max_iter=50, random_state=42)\n",
    "sgd_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "\n",
    "np.mean(cross_val_score(sgd_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06977d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6717109326744904 0.4681446405510116\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = cross_val_predict(sgd_cl, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26ee82fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision vs. Recall based on thresholds\n",
    "\n",
    "Y_sgd_scores = cross_val_predict(sgd_cl, X_train_num_cat_scaled, Y_train, cv=10, method='decision_function')\n",
    "precisions_sgd, recalls_sgd, thresholds_sgd = precision_recall_curve(Y_train, Y_sgd_scores)\n",
    "\n",
    "prec_rec_threshold(precisions_sgd, recalls_sgd, thresholds_sgd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "847740aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# In order to increase the precision and allow a decrease in the recall, set the threshold greater than 0.5.\\n# This will give the precision greater than 0.77\\n\\nY_train_pred_90 = (Y_scores > 0.5)\\nprint(precision_score(Y_train, Y_train_pred_90), recall_score(Y_train, Y_train_pred_90))'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# In order to increase the precision and allow a decrease in the recall, set the threshold greater than 0.5.\n",
    "# This will give the precision greater than 0.77\n",
    "\n",
    "Y_train_pred_90 = (Y_scores > 0.5)\n",
    "print(precision_score(Y_train, Y_train_pred_90), recall_score(Y_train, Y_train_pred_90))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe966c58",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696f185",
   "metadata": {},
   "source": [
    "<a id='KNN'></a>\n",
    "\n",
    "### KNN (Accuracy: 78.0% / Precision: 54.5% / Recall: 27.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f58a6453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806793260282368"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cl = KNeighborsClassifier(n_neighbors=9)\n",
    "knn_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "np.mean(cross_val_score(knn_cl, X_train_num_cat_scaled, Y_train, cv=10, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4da422c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5452604611443211 0.2748600947051227\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = cross_val_predict(knn_cl, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008cb3f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b3678",
   "metadata": {},
   "source": [
    "### Soft Voting (Scaled: 87.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df117621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Voting (logistic regression, random forest, support vector machine)\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(eval_metric='error', use_label_encoder=False)\n",
    "log_cl = LogisticRegression(solver=\"lbfgs\", C=10, max_iter=3000)\n",
    "#rnd_clf = RandomForestClassifier(n_estimators=300, max_leaf_nodes=20, n_jobs=-1, oob_score=True)\n",
    "svm_cl = SVC(random_state=1, coef0=0, C=1, gamma= 'scale', kernel='rbf', decision_function_shape='ovo', probability=True)\n",
    "\n",
    "voting_cl = VotingClassifier(estimators = [('lr', log_cl), ('xgb', xgb_cl), ('svc', svm_cl)], voting='soft')\n",
    "voting_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "\n",
    "\n",
    "for clf in (log_cl, xgb_cl, svm_cl, voting_cl):\n",
    "    clf.fit(X_train_num_cat_scaled, Y_train)\n",
    "    Y_pred = clf.predict(X_test_num_cat_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f35eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = cross_val_predict(voting_cl, X_train_num_cat_scaled, Y_train, cv=10)\n",
    "print(precision_score(Y_train, Y_train_pred), recall_score(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a6a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59afb272",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The estimator Sequential should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-5813aa8c9be2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvoting_cl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rnd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_cl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'xgb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_cl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mvoting_cl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_num_cat_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         if (self.weights is not None and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'drop'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    242\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m    243\u001b[0m                         \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator Sequential should be a classifier."
     ]
    }
   ],
   "source": [
    "# Soft Voting (logistic regression, random forest, support vector machine)\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier(eval_metric='error', use_label_encoder=False)\n",
    "rnd_cl = RandomForestClassifier(n_estimators=300, max_leaf_nodes=20, n_jobs=-1, oob_score=True)\n",
    "svm_cl = SVC(random_state=1, coef0=0, C=1, gamma= 'scale', kernel='rbf', decision_function_shape='ovo', probability=True)\n",
    "\n",
    "voting_cl = VotingClassifier(estimators = [('rnd', rnd_cl), ('xgb', xgb_cl), ('svc', svm_cl)], voting='soft')\n",
    "voting_cl.fit(X_train_num_cat_scaled, Y_train)\n",
    "\n",
    "\n",
    "for clf in (rnd_cl, xgb_cl, svm_cl, voting_cl):\n",
    "    clf.fit(X_train_num_cat_scaled, Y_train)\n",
    "    Y_pred = clf.predict(X_test_num_cat_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620e340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552297c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e39cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3e986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ec564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dac8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472d202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
